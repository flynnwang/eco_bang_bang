defaults:


- override hydra/job_logging: default
- override hydra/hydra_logging: default

hydra:
  run:
    dir: /home/flynnwang/runs/ebb/${now:%m-%d}/${now:%H-%M-%S}

name: run_20250124_stage1_teacher_game_win_loss_v4

## WANDB params
# The wandb project name
project: lux_s3
# The wandb user to log to
entity: pyflynn
# The wandb group for the run
group: luxs3_v2_initial_test_sym_info
obs_space_kwargs:
  use_energy_cost_map: True

reward_space_kwargs: {}
reward_schema: game_win_loss2
#reward_schema: match_explore_win_loss
reward_shaping_params:
  use_hidden_relic_estimator: True
  energy_cost_change: 0
  match_observed: 0.5
  match_win: 1

## TRAINING params
total_steps: 3e8
num_actors: 12
n_actor_envs: 16

unroll_length: 16
# Batch must be multiple of `n_actor_envs`
batch_size: 4

discounting: 0.999

## MODEL params
model_arch: conv_model
n_blocks: 12
hidden_dim: 128
base_out_channels: 128
embedding_dim: 32
n_merge_layers: 1
normalize: False
sum_player_embeddings: False
use_index_select: False
rescale_value_input: True
rescale_se_input: True
# Conv-specific params
kernel_size: 5


## OPTIMIZER params
optimizer_class: Adam
optimizer_kwargs:
  lr: 5e-5
  # See https://arxiv.org/pdf/2105.05246.pdf
  eps: 0.0003
  #alpha: 0.9
min_lr_mod: 0.01

## LOSS params
#entropy_cost: 5e-3
#entropy_cost: 3e-3
#entropy_cost: 1e-3
entropy_cost: 2e-4
baseline_cost: 1.
teacher_kl_cost: 1e-3
#teacher_kl_cost: 5e-4
#teacher_kl_cost: 1e-4
teacher_baseline_cost: 0.0
# lambda parameter for TD-lambda and UPGO losses
lmb: 0.8
#lmb: 0.9
reduction: sum


# Pretrained model for KL loss
use_teacher: True
teacher_load_dir: /home/flynnwang/runs/ebb/01-26/23-37-59
teacher_checkpoint_file: 157622720.pt
#teacher_load_dir: /home/flynnwang/runs/ebb/01-26/06-15-08
#teacher_checkpoint_file: 080654272.pt
#teacher_load_dir: /home/flynnwang/runs/ebb/01-25/13-00-13
#teacher_checkpoint_file: 038262784.pt

# MISCELLANEOUS params
use_mixed_precision: True
max_one_gpu_actor_num: 0
actor_device: cuda:0
learner_device: cuda:1

#actor_device: cpu
#learner_device: cpu
model_log_freq: 100

# in minutes
checkpoint_freq: 20
# file_descriptor or file_system
sharing_strategy: file_system

disable_wandb: False
debug: False
#disable_wandb: True
#debug: True

#load_dir: /home/flynnwang/runs/ebb/01-27/07-10-29
#checkpoint_file: 064936384.pt
#load_dir: /home/flynnwang/runs/ebb/01-26/06-15-08
#checkpoint_file: 080654272.pt
#load_dir: /home/flynnwang/runs/ebb/01-25/23-02-54/
#checkpoint_file: 043695552.pt
#load_dir: /home/flynnwang/runs/ebb/01-25/20-36-34
#checkpoint_file: 011207616.pt
#load_dir: /home/flynnwang/runs/ebb/01-28/08-14-39
#checkpoint_file: 031808384.pt
load_dir:
checkpoint_file:
#
weights_only: False
n_value_warmup_batches: 1
